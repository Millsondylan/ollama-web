{
  "name": "Streaming Specialist",
  "domain": "sse-streaming",
  "version": "1.0",
  "expertise": [
    "server-sent-events",
    "ndjson-parsing",
    "streaming-timeouts",
    "heartbeat-mechanisms",
    "backpressure-handling"
  ],
  "api_contracts": {
    "POST /api/chat/stream": {
      "location": "server.js:1207-1372",
      "purpose": "Streaming chat with SSE",
      "request": {
        "message": "string (required)",
        "model": "string (optional)",
        "instructions": "string (optional)",
        "apiEndpoint": "string (optional)",
        "includeHistory": "boolean (optional)",
        "sessionId": "string (optional)",
        "attachments": "array (optional)"
      },
      "response": {
        "content_type": "text/event-stream",
        "charset": "utf-8",
        "headers": {
          "Cache-Control": "no-cache",
          "Connection": "keep-alive"
        },
        "events": [
          {
            "type": "data",
            "format": "data: {\"token\":\"...\"}\n\n",
            "description": "Incremental token from model"
          },
          {
            "type": "heartbeat",
            "format": ":heartbeat 1234567890\n\n",
            "interval": "15 seconds (STREAM_HEARTBEAT_INTERVAL_MS)",
            "purpose": "Prevent proxy/client timeouts"
          },
          {
            "type": "done",
            "format": "data: {\"done\":true,\"response\":\"...\",\"history\":[...],\"durationMs\":123}\n\n",
            "description": "Final event with full response"
          }
        ]
      }
    }
  },
  "patterns": {
    "streaming_guards": {
      "description": "CRITICAL: Disable all timeouts for streaming requests",
      "code_template": "function applyStreamingGuards(req, res, label) {\n  req.setTimeout(0);\n  res.setTimeout(0);\n  if (res.socket) {\n    res.socket.setTimeout(0);\n    res.socket.setKeepAlive(true);\n  }\n  req.on('close', () => {\n    console.log(`[${label}] Client disconnected`);\n  });\n  req.on('error', (err) => {\n    console.error(`[${label}] Request error:`, err.message);\n  });\n}",
      "location": "server.js:607-684",
      "critical": true,
      "reason": "Without this, streams abort at ~2 minutes due to Express defaults"
    },
    "sse_heartbeat": {
      "description": "Periodic comment-based heartbeat to keep connection alive",
      "code_template": "function startSseHeartbeat(res, label, metadata = {}) {\n  const interval = Number(process.env.STREAM_HEARTBEAT_INTERVAL_MS) || 15000;\n  const timer = setInterval(() => {\n    if (res.writableEnded) {\n      clearInterval(timer);\n      return;\n    }\n    res.write(`:heartbeat ${Date.now()}\\n\\n`);\n  }, interval);\n  res.on('close', () => clearInterval(timer));\n  return timer;\n}",
      "location": "server.js:647-684",
      "interval": "15 seconds default",
      "format": "SSE comment syntax (:...)",
      "purpose": "Prevent nginx/cloudflare/browser timeouts"
    },
    "ndjson_to_sse_conversion": {
      "description": "Convert Ollama NDJSON stream to SSE format",
      "code_template": "const reader = ollamaResponse.body.getReader();\nconst decoder = new TextDecoder();\nlet buffer = '';\n\nwhile (true) {\n  const { value, done } = await reader.read();\n  if (done) break;\n  \n  buffer += decoder.decode(value, { stream: true });\n  const lines = buffer.split('\\n');\n  buffer = lines.pop();\n  \n  for (const line of lines) {\n    if (!line.trim()) continue;\n    const chunk = JSON.parse(line);\n    \n    if (chunk.done) {\n      res.write(`data: ${JSON.stringify({ done: true, response: fullResponse, history, durationMs })}\\n\\n`);\n    } else if (chunk.response) {\n      res.write(`data: ${JSON.stringify({ token: chunk.response })}\\n\\n`);\n    }\n  }\n}",
      "location": "server.js:1207-1372",
      "input_format": "NDJSON from Ollama",
      "output_format": "SSE (data: {...}\\n\\n)"
    },
    "client_sse_parser": {
      "description": "Frontend SSE event parsing with buffer management",
      "code_template": "const reader = response.body.getReader();\nconst decoder = new TextDecoder();\nlet buffer = '';\n\nwhile (true) {\n  const { value, done } = await reader.read();\n  if (done) break;\n  \n  buffer += decoder.decode(value, { stream: true });\n  \n  let boundary;\n  while ((boundary = buffer.indexOf('\\n\\n')) !== -1) {\n    const rawEvent = buffer.slice(0, boundary).trim();\n    buffer = buffer.slice(boundary + 2);\n    \n    // Skip heartbeats\n    if (rawEvent.startsWith(':')) continue;\n    \n    const lines = rawEvent.split('\\n');\n    const dataLine = lines.find(line => line.startsWith('data:'));\n    if (!dataLine) continue;\n    \n    const payload = JSON.parse(dataLine.replace(/^data:\\s*/, ''));\n    \n    if (payload.done) {\n      // Handle completion\n    } else if (payload.token) {\n      // Handle token\n    }\n  }\n}",
      "location": "public/app.js:761-862",
      "key_points": [
        "Buffer incomplete events across chunks",
        "Parse events at \\n\\n boundaries",
        "Skip heartbeat comments",
        "Handle both token and done events"
      ]
    },
    "graceful_degradation": {
      "description": "Fallback from streaming to non-streaming on error",
      "code_template": "try {\n  await sendThinkingStream(payload, liveThinking, liveUser);\n} catch (streamError) {\n  console.warn('Thinking stream failed, falling back to standard chat');\n  const data = await fetchJson('/api/chat', {\n    method: 'POST',\n    body: JSON.stringify(payload)\n  });\n  // Handle non-streaming response\n}",
      "location": "public/app.js:691-714",
      "trigger": "Network errors, timeouts, or SSE parsing failures"
    }
  },
  "environment_variables": {
    "STREAM_HEARTBEAT_INTERVAL_MS": {
      "description": "Heartbeat frequency in milliseconds",
      "default": 15000,
      "type": "number",
      "recommendation": "10-30 seconds based on proxy timeout"
    },
    "OLLAMA_STREAM_TIMEOUT_MS": {
      "description": "Fetch timeout for streaming requests",
      "default": 0,
      "recommendation": "0 (disabled) for long generations",
      "note": "Use streaming guards instead"
    }
  },
  "common_mistakes": [
    {
      "mistake": "Not disabling timeouts on streaming routes",
      "impact": "Streams abort at ~2 minutes",
      "fix": "Call applyStreamingGuards(req, res) before streaming",
      "location": "server.js:607-684",
      "severity": "CRITICAL"
    },
    {
      "mistake": "Forgetting to send heartbeats",
      "impact": "Proxies/browsers close idle connections after 60-120s",
      "fix": "Call startSseHeartbeat(res, label) and clear on close",
      "location": "server.js:647-684"
    },
    {
      "mistake": "Incomplete SSE event buffering on client",
      "impact": "Parsing errors, missed tokens",
      "fix": "Buffer at \\n\\n boundaries, handle partial chunks",
      "location": "public/app.js:761-862"
    },
    {
      "mistake": "Not handling client disconnect",
      "impact": "Ollama streams continue wasting resources",
      "fix": "Listen to req.on('close') and abort fetch/cleanup",
      "example": "req.on('close', () => { abortController.abort(); })"
    },
    {
      "mistake": "Assuming SSE data: lines are complete JSON",
      "impact": "JSON.parse() errors on split chunks",
      "fix": "Accumulate buffer until \\n\\n, then parse complete event"
    }
  ],
  "performance_considerations": {
    "buffer_size": {
      "recommendation": "Use streaming decode with { stream: true }",
      "reason": "Prevents memory buildup on large responses"
    },
    "heartbeat_overhead": {
      "bytes_per_heartbeat": "~25 bytes",
      "frequency": "Every 15s",
      "total_overhead": "~100 bytes/minute (negligible)"
    },
    "backpressure": {
      "note": "Express handles backpressure automatically",
      "manual_control": "Check res.write() return value for pausing"
    }
  },
  "debugging": {
    "enable_logging": "Set DEBUG=stream in environment",
    "key_metrics": [
      "Time to first token (TTFT)",
      "Tokens per second (TPS)",
      "Heartbeat count",
      "Client disconnect events"
    ],
    "common_issues": {
      "no_tokens_received": "Check Ollama connectivity, model availability",
      "stream_cuts_off": "Verify timeout guards, check heartbeat logs",
      "duplicate_tokens": "Check for double event parsing in client buffer logic"
    }
  },
  "testing": {
    "verification_script": "scripts/verify.js::verifyChatStream()",
    "test_points": [
      "First token latency < 5s",
      "Heartbeat every 15-20s",
      "Final done event received",
      "Client abort cleanup"
    ],
    "manual_test": "curl -N http://localhost:3000/api/chat/stream -H 'Content-Type: application/json' -d '{\"message\":\"test\"}'"
  }
}
